How to Clear Hadoop Disk Space in BDP
-------------------------------------
Problem:  The RDA Deployer is not working because we're low on disk space in Hadoop
Solution: Erase a bunch of files in Hadoop


Procedure
---------
 1. Connect to a data node on the cluster
    a. ssh to the puppet master
    b. Run these commands:
       unix> go datanodes

       unix> sudo -s
       unix> su - yarn    # become the yarn user so we can delete anything in Hadoop


 2. Use the yarn user to delete a bunch of files

    a. Get the total amount of space Hadoop is using  *BEFORE* deleting files
       unix> hadoop fs -du -s -h /

    b. Determine which directories are using the most amount of space
       unix> hadoop fs -du -h -s /accumulo /bdp-ingest /pg_backups /pg_log_backups /rda /storage /tmp /user /var

    c. Delete some BDP files
       unix> hadoop fs -rm -r -skipTrash /rda/backups/*
       unix> hadoop fs -rm -r -skipTrash /pg_log_backups/*       # delete postgres log backups
       unix> hadoop fs -rm -r -skipTrash /pg_backups/*           # delete postgres backups

    d. Get the total amount of space Hadoop is using  *AFTER* deleting files
       unix> hadoop fs -du -s -h /


